import pandas as pd
import numpy as np
from etl.ai_roaster import AIRoaster

class DataRoaster:
    """
    Classe principal de processamento de dados.
    ResponsÃ¡vel por extrair mÃ©tricas tÃ©cnicas e orquestrar a geraÃ§Ã£o de insights (Regras + IA).
    """
    
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.metrics = {}
        self.roast_comments = []

    def analyze(self) -> dict:
        """Executa o profiling completo do dataset e chama a IA."""
        
        # 1. CÃ¡lculo de MÃ©tricas TÃ©cnicas (Hard Skills)
        self.metrics['shape'] = self.df.shape
        # Converte bytes para MB
        self.metrics['memory_mb'] = round(self.df.memory_usage(deep=True).sum() / (1024 ** 2), 2)
        self.metrics['duplicates'] = self.df.duplicated().sum()
        self.metrics['columns'] = list(self.df.columns)
        
        # AnÃ¡lise de Nulos (% por coluna)
        null_counts = self.df.isnull().sum()
        self.metrics['null_percent'] = ((null_counts / len(self.df)) * 100).round(2).to_dict()
        
        # 2. GeraÃ§Ã£o de Roasts Baseados em Regras (LÃ³gica de NegÃ³cio)
        self._generate_rule_based_roasts()
        
        # 3. GeraÃ§Ã£o de Roast via IA (Llama 3 / Groq)
        # try/except para garantir que o sistema funcione mesmo sem API Key
        try:
            ai = AIRoaster()
            ai_comment = ai.generate_roast(self.metrics)
            # Insere o comentÃ¡rio da IA no topo da lista com destaque
            self.roast_comments.insert(0, f"ğŸ¤– [AI OPINION]: {ai_comment}")
        except Exception as e:
            # Falha silenciosa da IA, logamos apenas no console
            print(f"Warning: AI Roast failed via API. Reason: {e}")
            self.roast_comments.append("âš ï¸ [SYSTEM]: A IA estÃ¡ tirando um cochilo (Verifique sua API Key), mas as regras manuais rodaram.")

        return self.metrics

    def _generate_rule_based_roasts(self):
        """Gera comentÃ¡rios baseados em regras estÃ¡ticas (Fallback e SeguranÃ§a)."""
        
        # Regra 1: Integridade de Linhas (Duplicatas)
        if self.metrics['duplicates'] > 0:
            pct_dup = (self.metrics['duplicates'] / self.metrics['shape'][0]) * 100
            if pct_dup > 10:
                self.roast_comments.append(f"ğŸ”¥ ALERTA CRÃTICO: {self.metrics['duplicates']} linhas duplicadas ({pct_dup:.1f}% do total). Isso distorce qualquer KPI.")
            else:
                self.roast_comments.append(f"âš ï¸ AtenÃ§Ã£o: Encontramos {self.metrics['duplicates']} duplicatas. Remova antes do load.")

        # Regra 2: Qualidade dos Dados (Sparsity/Nulls)
        clean_dataset = True
        for col, pct in self.metrics['null_percent'].items():
            if pct > 40:
                clean_dataset = False
                self.roast_comments.append(f"ğŸ—‘ï¸ A coluna '{col}' Ã© praticamente lixo ({pct}% nula). Avalie dropar do schema.")
            elif pct > 10:
                clean_dataset = False
                self.roast_comments.append(f"âš ï¸ '{col}' tem {pct}% de dados faltantes. Cuidado com joins nessa chave.")

        # Regra 3: OtimizaÃ§Ã£o de Performance
        if self.metrics['memory_mb'] > 100:
            self.roast_comments.append(f"ğŸŒ Dataset pesado ({self.metrics['memory_mb']}MB). Se for processar isso no Pandas sem Chunking, vai estourar a RAM.")

        # Elogio (raro, mas possÃ­vel)
        if clean_dataset and self.metrics['duplicates'] == 0:
            self.roast_comments.append("âœ… (Regra): Estruturalmente o dado parece sÃ³lido. Surpreendente.")

    def get_roast(self) -> list:
        """Retorna a lista final de feedbacks."""
        return self.roast_comments